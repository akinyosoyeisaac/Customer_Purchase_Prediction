{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014f16f0-7de5-4906-aae3-dee6e7d9754c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MODEL BASELINE\n",
    "## In this notebook we will be building a logistic regression model\n",
    "*  We will be using the logistic model as a baseline model to checkmate the performance of other model we will be using in getting at our final model.\n",
    "> FLOW\n",
    ">>\n",
    ">> Having know that our data is still imbalance despite the feature engineering, to ensure that this those not affect the performance of our model our train data will be splitted into train and validation set using ```stratifiedshufflesplit``` to ensure there are equal representation of each of the class to be predicted in our train and validation set.\n",
    ">>\n",
    ">> The train set is further augmented for class balance using the ```randomoversampler``` this is to ensure that our model is not just craming the train set and to avoid over generalization\n",
    ">>\n",
    ">> After this we train our model on the train set and evaluate it on the validation set using confusion matrix\n",
    ">>\n",
    ">> We are also interested in understanding the contribution of each features in our model\n",
    ">>\n",
    "> **Note this workflow is applicable to all the other models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c8b6e-3181-4e33-9c71-55343275862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.style.use(\"seaborn-dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895d9653-b58e-4f63-acb5-524cd2bc66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to train, test data\n",
    "test_pth = \"test_Wf7sxXF.csv\"\n",
    "train_pth = \"train_wn75k28.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7426f8e9-ed2e-46cf-899d-f73e2a2bfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling our data, this process is derived from the feature engineering section\n",
    "\n",
    "def wrangling(path):\n",
    "    df = pd.read_csv(path, index_col='id')\n",
    "    \n",
    "    # Removing missing values for products_purchased and signup_date for products not purchased\n",
    "    product_not_bought = df[df[\"buy\"] == 0]\n",
    "    product_not_bought_purchased_isna = product_not_bought[product_not_bought[\"products_purchased\"].isna()]\n",
    "    index_purchased_isna = product_not_bought_purchased_isna.index\n",
    "    df.drop(index = index_purchased_isna, inplace=True)\n",
    "    \n",
    "    product_not_bought = df[df[\"buy\"] == 0]\n",
    "    product_not_bought_signup_date= product_not_bought[product_not_bought[\"signup_date\"].isna()]\n",
    "    index_signup_date_isna = product_not_bought_signup_date.index\n",
    "    df.drop(index = index_signup_date_isna, inplace=True)\n",
    "    \n",
    "    # Summing all the user activity\n",
    "    user_activity_col = [x for x in df.columns if x.startswith(\"user\")]\n",
    "    df[\"sum_user_activities\"] = np.sum([df[x] for x in user_activity_col], 0)\n",
    "    \n",
    "    # Making the date columns usable for our model\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "    df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], format=\"%Y-%m-%d\")\n",
    "    day = df[\"created_at\"] - df[\"signup_date\"]\n",
    "    day = day.replace({np.nan:day.max()})\n",
    "    day = day.astype('str').str.split(\" \", expand=True)[0]\n",
    "    day[\"day\"] = np.abs(day.astype('int'))\n",
    "    \n",
    "    # Summing the campaign vars in the data\n",
    "    camp_col = [x for x in df.columns if x.startswith(\"camp\")]\n",
    "    df[\"sum_camp\"] = np.sum([df[x] for x in camp_col], 0)\n",
    "    \n",
    "    # imputting missing value\n",
    "    df[\"products_purchased\"] = df[\"products_purchased\"].fillna(0)\n",
    "    \n",
    "    # Removing unwanted columns\n",
    "    df.drop(columns = camp_col + [\"created_at\", \"signup_date\"] + user_activity_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7dd930-15b0-4d7a-8cf3-4dfba72c280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our train data into our notebook\n",
    "df = wrangling(train_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ed267d-0d9c-41ea-820b-e14dfcd20d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature and label for our data using X and y respectively\n",
    "X = df.drop(columns=\"buy\")\n",
    "y = df[\"buy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f73c59-5f92-48df-b91e-5133faa453f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data into train and validation set, with 80% used for training and 20% for validation\n",
    "sss = StratifiedShuffleSplit(n_splits= 100, test_size=0.2, random_state=234)\n",
    "for train_index, val_index in sss.split(X, y):\n",
    "    X_train, y_train = X.copy().iloc[train_index], y.copy().iloc[train_index]\n",
    "    X_val, y_val = X.copy().iloc[val_index], y.copy().iloc[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200c4d2-837d-4915-b633-c1493d3b1513",
   "metadata": {},
   "source": [
    "### DEALING WITH IMBALANCE\n",
    "* As it has been pointed out earlier that our data is imbalance we train and up scale the class with less count which in the case is class 1 and the approach taken is to scale the train set to 10,000 from 1598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6417e53e-c301-4a23-bb4d-04e791fb3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state of class before augmenting\n",
      " 0    10762\n",
      "1     1598\n",
      "Name: buy, dtype: int64\n",
      "\n",
      "Final state of class after augmenting\n",
      " 0    10762\n",
      "1    10000\n",
      "Name: buy, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial state of class before augmenting\\n\", y_train.value_counts(), end=\"\\n\\n\") # Checking the class count of train set before augmentation\n",
    "\n",
    "resampler = RandomOverSampler(sampling_strategy={0:10762, 1:10000}, random_state=234)\n",
    "X_res, y_res = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Final state of class after augmenting\\n\", y_res.value_counts()) # Checking the class count of train set before augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516aa985-b88a-48b2-bec7-11f1797ea1f5",
   "metadata": {},
   "source": [
    "### BUILDING MODEL\n",
    "* In building the model the following will be considered\n",
    "1. Imputting missing values\n",
    "2. Because of the high range between our data we are going to be standardizing it\n",
    "3. Finally we will define our logistic regression model\n",
    "* All this phase will be put to gather using a pipeline to afford redundancy and reuseability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e2bbc61-5e2d-4ac6-8dfb-28531b1ff3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing values', SimpleImputer()),\n",
       "                ('Standardardization', StandardScaler()),\n",
       "                ('model', LogisticRegression(class_weight='balanced'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining our model\n",
    "log_model = Pipeline([(\"missing values\",SimpleImputer()), \n",
    "                      (\"Standardardization\", StandardScaler()), \n",
    "                      (\"model\",LogisticRegression(class_weight=\"balanced\"))])\n",
    "\n",
    "# fitting our data to the model\n",
    "log_model.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf612f9-7b15-4413-81e0-8e7c29935cec",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION\n",
    "* The model is evaluated using precision, recall, f1 score and accuracy which is as display below\n",
    "* The model is evaluation not only on the validation set but also on the train set this is to check that our model is not overfitting\n",
    "* Also, the performance of our model can also be visualized as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5754e5a-e918-4d15-bd2c-26e4d163d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87      2691\n",
      "           1       0.36      0.79      0.49       400\n",
      "\n",
      "    accuracy                           0.79      3091\n",
      "   macro avg       0.66      0.79      0.68      3091\n",
      "weighted avg       0.88      0.79      0.82      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the validation set\n",
    "print(classification_report(y_val, log_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4112363d-9725-458a-93e0-e774d779f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87     10762\n",
      "           1       0.37      0.79      0.50      1598\n",
      "\n",
      "    accuracy                           0.80     12360\n",
      "   macro avg       0.67      0.80      0.69     12360\n",
      "weighted avg       0.89      0.80      0.83     12360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the train set\n",
    "print(classification_report(y_train, log_model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51046448-f700-4b3d-b61a-6e893a857f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inpecting the perfomance of our model using confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(log_model, X_val, y_val, normalize=\"true\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ee466-b8d5-4ae8-bc8b-52cf4ff95455",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FEATURE IMPORTANCE\n",
    "* Using the coffient of our model we can have an understanding of the contribution of the each feature to the performance of the model\n",
    "* from the table below we can judge that the user_activities greatly contribute to whether a product will be bought or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2809c005-f792-4465-9e2c-e3f5e5ca0cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d28fd_row0_col1 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d28fd_row1_col1 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d28fd_row2_col1 {\n",
       "  background-color: #a4bcda;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d28fd_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >feature</th>\n",
       "      <th class=\"col_heading level0 col1\" >importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d28fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d28fd_row0_col0\" class=\"data row0 col0\" >products_purchased</td>\n",
       "      <td id=\"T_d28fd_row0_col1\" class=\"data row0 col1\" >-1.214280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d28fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d28fd_row1_col0\" class=\"data row1 col0\" >sum_user_activities</td>\n",
       "      <td id=\"T_d28fd_row1_col1\" class=\"data row1 col1\" >1.313668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d28fd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d28fd_row2_col0\" class=\"data row2 col0\" >sum_camp</td>\n",
       "      <td id=\"T_d28fd_row2_col1\" class=\"data row2 col1\" >-0.255607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25bf2fea508>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the coeffient of our model\n",
    "coeffient = log_model.named_steps[\"model\"].coef_ \n",
    "feature_importance = pd.DataFrame({\"importance\":coeffient[0], \"feature\":X.columns})[[\"feature\", \"importance\"]]\n",
    "feature_importance.style.background_gradient(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff3458-0c57-4c4b-8f3a-899f9709c416",
   "metadata": {},
   "source": [
    "### RUNNING PREDICTION ON AN UNKNOWN DATA\n",
    "* We use our model to predict a new data\n",
    "* We are going to wraggle our new data to get it to the stage of it been accepted by our model else it will thrown error at our face\n",
    "* Then we run a prediction on the model\n",
    "* Our prediction will be output as a CSV file which can be shared with our stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ef1884-c592-45b3-be1e-0c873e1ece9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangling function for our test data which is an extract of the wrangling for the train data\n",
    "def wrangling_test(path):\n",
    "    df = pd.read_csv(path, index_col='id')\n",
    "    \n",
    "    # Summing all the user activity\n",
    "    user_activity_col = [x for x in df.columns if x.startswith(\"user\")]\n",
    "    df[\"sum_user_activities\"] = np.sum([df[x] for x in user_activity_col], 0)\n",
    "    \n",
    "    # Making the date columns usable for our model\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], format=\"%Y-%m-%d\")\n",
    "    df[\"signup_date\"] = pd.to_datetime(df[\"signup_date\"], format=\"%Y-%m-%d\")\n",
    "    day = df[\"created_at\"] - df[\"signup_date\"]\n",
    "    day = day.replace({np.nan:day.max()})\n",
    "    day = day.astype('str').str.split(\" \", expand=True)[0]\n",
    "    day[\"day\"] = np.abs(day.astype('int'))\n",
    "    \n",
    "    # Summing the campaign vars in the data\n",
    "    camp_col = [x for x in df.columns if x.startswith(\"camp\")]\n",
    "    df[\"sum_camp\"] = np.sum([df[x] for x in camp_col], 0)\n",
    "    \n",
    "    # imputting missing value\n",
    "    df[\"products_purchased\"] = df[\"products_purchased\"].fillna(0)\n",
    "    \n",
    "    # Removing unwanted columns\n",
    "    df.drop(columns = camp_col + [\"created_at\", \"signup_date\"] + user_activity_col, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc63419d-a195-4176-884e-fe2d7ede8346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>products_purchased</th>\n",
       "      <th>sum_user_activities</th>\n",
       "      <th>sum_camp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39162</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39163</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39164</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39165</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39166</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       products_purchased  sum_user_activities  sum_camp\n",
       "id                                                      \n",
       "39162                 0.0                    4         4\n",
       "39163                 3.0                    2        11\n",
       "39164                 0.0                    2        15\n",
       "39165                 2.0                    5        17\n",
       "39166                 2.0                    1         9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the wrangling function to our test data\n",
    "X_test = wrangling_test(test_pth)\n",
    "X_test.head() # Previewing our data after wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34bd7c07-027e-4d4f-bff6-af1271ff9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the class label for our test data\n",
    "test_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48738c12-650b-4a96-a093-d4960a23ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42490</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43973</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44795</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44716</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buy\n",
       "id        \n",
       "44103    1\n",
       "42490    0\n",
       "43973    1\n",
       "44795    1\n",
       "44716    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing our test_pred in a dataframe\n",
    "test_pred_df = pd.DataFrame({\"buy\":test_pred, \"id\":X_test.index}).set_index(\"id\")\n",
    "test_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "948b49ee-6a1c-4404-9112-0c20fd265904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# Extracting our model name from the model using regex\n",
    "import re # importing regex\n",
    "\n",
    "# Model name extractor and stored using the variable name model_name\n",
    "model_name = (re.match(\"[A-Za-z]*\", str(log_model.named_steps[\"model\"].__class__)\n",
    "              .split(\".\")[-1])\n",
    "              .group(0)\n",
    "             )\n",
    "print(\"model name:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d52ac89-4a7f-4e78-8b74-0de80d3a56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting our predicted labels to csv\n",
    "test_pred_df.to_csv(model_name + \"_model.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
